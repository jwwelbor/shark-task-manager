# System Design: Shark Task Manager

**Application**: Shark Task Manager
**Version**: 1.0
**Date**: 2025-12-16
**Architecture Pattern**: Clean Architecture with Repository Pattern
**Tech Stack**: Go 1.23.4 + SQLite3 + Cobra CLI

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [System Overview](#system-overview)
3. [Architecture](#architecture)
4. [Component Design](#component-design)
5. [Data Architecture](#data-architecture)
6. [Interface Contracts](#interface-contracts)
7. [Non-Functional Requirements](#non-functional-requirements)
8. [Deployment Architecture](#deployment-architecture)
9. [Security Design](#security-design)
10. [Operations & Monitoring](#operations--monitoring)

---

## Executive Summary

### Purpose

Shark Task Manager is a task management system designed for AI-driven development workflows. It provides both an HTTP API and a powerful CLI (`shark`) for managing epics, features, and tasks with progress tracking, dependency management, and history auditing.

### Key Architectural Decisions

| Decision | Rationale | Trade-offs |
|----------|-----------|------------|
| **Go** | Excellent performance, built-in concurrency, static typing, single binary deployment | Smaller ecosystem than Python/Node, manual dependency management |
| **SQLite** | Zero-configuration, embedded database, perfect for single-machine deployments | Not suitable for distributed systems, single-writer at a time |
| **Repository Pattern** | Clean separation of data access from business logic, testable | More code than direct database access |
| **Cobra CLI** | Industry-standard CLI framework, excellent UX, subcommand support | Framework dependency |
| **No ORM** | Direct SQL control, better performance, clearer queries | More boilerplate code, manual mapping |

### Target Use Case

- **Primary**: AI agent task orchestration for software development
- **Secondary**: Developer productivity CLI for project management
- **Deployment**: Local development machine, single user
- **Scale**: Thousands of tasks, hundreds of features, dozens of epics

---

## System Overview

### High-Level Architecture

```mermaid
graph LR
    subgraph "Presentation Layer"
        CLI[Shark CLI Tool]
    end

    subgraph "Business Layer"
        Models[Domain Models]
        Validation[Validation Logic]
    end

    subgraph "Data Access Layer"
        EpicRepo[Epic Repository]
        FeatureRepo[Feature Repository]
        TaskRepo[Task Repository]
        HistoryRepo[History Repository]
    end

    subgraph "Infrastructure Layer"
        DB[SQLite Database]
        Schema[Schema Management]
    end

    CLI --> Models
    Models --> Validation
    Models --> EpicRepo
    Models --> FeatureRepo
    Models --> TaskRepo
    Models --> HistoryRepo
    EpicRepo --> DB
    FeatureRepo --> DB
    TaskRepo --> DB
    HistoryRepo --> DB
    Schema --> DB
```

### Technology Stack

| Layer | Technology | Version | Purpose |
|-------|-----------|---------|---------|
| **Language** | Go | 1.23.4 | Application runtime |
| **Database** | SQLite | 3.x | Embedded data storage |
| **CLI Framework** | Cobra | 1.10.2 | Command-line interface |
| **Config** | Viper | 1.21.0 | Configuration management |
| **UI** | pterm | 0.12.82 | Terminal UI components |
| **Testing** | testify | 1.11.1 | Test assertions |
| **Database Driver** | go-sqlite3 | 1.14.32 | SQLite CGO binding |

### Directory Structure

```
shark-task-manager/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ server/           # HTTP server entry point
â”‚   â”œâ”€â”€ pm/              # CLI tool entry point
â”‚   â”œâ”€â”€ demo/            # Demo application
â”‚   â””â”€â”€ test-db/         # Database test utility
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ models/          # Domain entities
â”‚   â”‚   â”œâ”€â”€ epic.go
â”‚   â”‚   â”œâ”€â”€ feature.go
â”‚   â”‚   â”œâ”€â”€ task.go
â”‚   â”‚   â”œâ”€â”€ task_history.go
â”‚   â”‚   â””â”€â”€ validation.go
â”‚   â”œâ”€â”€ repository/      # Data access layer
â”‚   â”‚   â”œâ”€â”€ repository.go
â”‚   â”‚   â”œâ”€â”€ epic_repository.go
â”‚   â”‚   â”œâ”€â”€ feature_repository.go
â”‚   â”‚   â”œâ”€â”€ task_repository.go
â”‚   â”‚   â””â”€â”€ task_history_repository.go
â”‚   â”œâ”€â”€ db/              # Database initialization
â”‚   â”‚   â””â”€â”€ db.go
â”‚   â”œâ”€â”€ cli/             # CLI infrastructure
â”‚   â”‚   â”œâ”€â”€ root.go
â”‚   â”‚   â””â”€â”€ commands/    # CLI commands
â”‚   â”œâ”€â”€ formatters/      # Output formatting
â”‚   â””â”€â”€ test/            # Test utilities
â”œâ”€â”€ docs/                # Documentation
â”œâ”€â”€ Makefile             # Build automation
â””â”€â”€ go.mod               # Go module definition
```

---

## Architecture

### Layered Architecture Pattern

#### Layer 1: Presentation Layer

**Responsibilities**:
- Handle user input (HTTP requests, CLI commands)
- Format output (JSON, table, text)
- Input validation (basic)
- Error handling and user feedback

**Components**:
- `cmd/server/main.go` - HTTP server with health checks
- `cmd/pm/main.go` - CLI entry point
- `internal/cli/commands/` - CLI command implementations
- `internal/formatters/` - Output formatting

**Dependencies**: â†“ Business Layer

#### Layer 2: Business Layer

**Responsibilities**:
- Domain model definitions
- Business rule validation
- Data transformation
- Status transitions

**Components**:
- `internal/models/epic.go` - Epic entity with validation
- `internal/models/feature.go` - Feature entity with validation
- `internal/models/task.go` - Task entity with validation
- `internal/models/validation.go` - Shared validation rules

**Dependencies**: â†“ Data Access Layer

#### Layer 3: Data Access Layer

**Responsibilities**:
- CRUD operations
- Query construction
- Transaction management
- Progress calculations

**Components**:
- `internal/repository/epic_repository.go` - Epic data access
- `internal/repository/feature_repository.go` - Feature data access
- `internal/repository/task_repository.go` - Task data access
- `internal/repository/task_history_repository.go` - History tracking

**Dependencies**: â†“ Infrastructure Layer

#### Layer 4: Infrastructure Layer

**Responsibilities**:
- Database connection management
- Schema creation and migration
- SQLite configuration
- Connection pooling

**Components**:
- `internal/db/db.go` - Database initialization and schema

**Dependencies**: SQLite database file

### Dependency Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  External Dependencies (Imports)        â”‚
â”‚  â€¢ Database file (shark-tasks.db)      â”‚
â”‚  â€¢ Configuration files                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Infrastructure Layer                    â”‚
â”‚  â€¢ Database connection                  â”‚
â”‚  â€¢ Schema management                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Access Layer                      â”‚
â”‚  â€¢ Repositories                         â”‚
â”‚  â€¢ Query builders                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Business Layer                         â”‚
â”‚  â€¢ Domain models                        â”‚
â”‚  â€¢ Validation                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Presentation Layer                     â”‚
â”‚  â€¢ HTTP handlers                        â”‚
â”‚  â€¢ CLI commands                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Principle**: Dependencies point inward. Outer layers depend on inner layers, never vice versa.

---

## Component Design

### 1. Domain Models

#### Epic Model

**Purpose**: Top-level organizational unit for grouping related features

**Structure**:
```go
type Epic struct {
    ID            int64
    Key           string      // Unique identifier (e.g., "E04")
    Title         string
    Description   *string
    Status        EpicStatus  // draft, active, completed, archived
    Priority      Priority    // high, medium, low
    BusinessValue *Priority   // high, medium, low
    CreatedAt     time.Time
    UpdatedAt     time.Time
}
```

**Validation Rules**:
- Key must match pattern: `E[0-9]{2,}` (e.g., E01, E10, E100)
- Title is required
- Status must be one of: draft, active, completed, archived
- Priority is required: high, medium, low

**Business Rules**:
- Progress is calculated as weighted average of feature progress
- Features are weighted by task count

#### Feature Model

**Purpose**: Mid-level component within an epic

**Structure**:
```go
type Feature struct {
    ID           int64
    EpicID       int64
    Key          string      // e.g., "E04-F01"
    Title        string
    Description  *string
    Status       FeatureStatus
    ProgressPct  float64     // 0.0 to 100.0
    CreatedAt    time.Time
    UpdatedAt    time.Time
}
```

**Validation Rules**:
- Key must match: `E[0-9]{2,}-F[0-9]{2,}`
- Progress must be 0.0 to 100.0
- Status: draft, active, completed, archived

**Business Rules**:
- Progress calculated from task completion ratios
- Formula: `(completed + ready_for_review) / total * 100`

#### Task Model

**Purpose**: Atomic work unit within a feature

**Structure**:
```go
type Task struct {
    ID            int64
    FeatureID     int64
    Key           string          // e.g., "E04-F01-T001"
    Title         string
    Description   *string
    Status        TaskStatus      // todo, in_progress, blocked, ready_for_review, completed, archived
    AgentType     *AgentType      // frontend, backend, api, testing, devops, general
    Priority      int             // 1-10 (1=highest)
    DependsOn     *string         // JSON array of task keys
    AssignedAgent *string
    FilePath      *string
    BlockedReason *string
    CreatedAt     time.Time
    StartedAt     sql.NullTime
    CompletedAt   sql.NullTime
    BlockedAt     sql.NullTime
    UpdatedAt     time.Time
}
```

**Validation Rules**:
- Key must match: `E[0-9]{2,}-F[0-9]{2,}-T[0-9]{3,}`
- Priority: 1 to 10
- Status transitions enforced by repository
- DependsOn must be valid JSON array

**Business Rules**:
- Timestamps set automatically on status transitions
- History record created on every status change
- Blocked tasks must have blocked_reason

### 2. Repository Pattern

#### Repository Interface (Recommended Future Enhancement)

```go
type TaskRepository interface {
    // CRUD
    Create(ctx context.Context, task *Task) error
    GetByID(ctx context.Context, id int64) (*Task, error)
    GetByKey(ctx context.Context, key string) (*Task, error)
    Update(ctx context.Context, task *Task) error
    Delete(ctx context.Context, id int64) error

    // Queries
    ListByFeature(ctx context.Context, featureID int64) ([]*Task, error)
    ListByEpic(ctx context.Context, epicKey string) ([]*Task, error)
    FilterByStatus(ctx context.Context, status TaskStatus) ([]*Task, error)

    // Operations
    UpdateStatus(ctx context.Context, taskID int64, status TaskStatus, agent, notes *string) error
    BlockTask(ctx context.Context, taskID int64, reason string, agent *string) error
    UnblockTask(ctx context.Context, taskID int64, agent *string) error
}
```

**Current Implementation**: Concrete struct without interface

**Benefits of Adding Interface**:
- Mockable for testing
- Swappable implementations (SQLite â†’ PostgreSQL)
- Clear API contracts

### 3. Database Layer

#### Connection Management

```go
type DB struct {
    *sql.DB
}

func NewDB(db *sql.DB) *DB {
    return &DB{db}
}

func (db *DB) BeginTx() (*sql.Tx, error) {
    return db.Begin()
}
```

**Features**:
- Wraps `sql.DB` for additional methods
- Connection pooling via Go's `database/sql`
- Transaction support

**SQLite Configuration**:
```go
PRAGMA foreign_keys = ON;           // Referential integrity
PRAGMA journal_mode = WAL;          // Write-Ahead Logging
PRAGMA busy_timeout = 5000;         // 5-second lock timeout
PRAGMA synchronous = NORMAL;        // Balance safety/performance
PRAGMA cache_size = -64000;         // 64MB cache
```

### 4. CLI Architecture

#### Command Structure

```
pm (root)
â”œâ”€â”€ epic
â”‚   â”œâ”€â”€ list
â”‚   â”œâ”€â”€ create
â”‚   â”œâ”€â”€ show
â”‚   â””â”€â”€ delete
â”œâ”€â”€ feature
â”‚   â”œâ”€â”€ list
â”‚   â”œâ”€â”€ create
â”‚   â”œâ”€â”€ show
â”‚   â””â”€â”€ delete
â””â”€â”€ task
    â”œâ”€â”€ list
    â”œâ”€â”€ create
    â”œâ”€â”€ show
    â”œâ”€â”€ update
    â”œâ”€â”€ start
    â”œâ”€â”€ complete
    â”œâ”€â”€ block
    â””â”€â”€ unblock
```

**Framework**: Cobra (industry standard)
**Configuration**: Viper for config file support
**Output Formatting**: pterm for rich terminal UI

---

## Data Architecture

### Entity-Relationship Diagram

```mermaid
erDiagram
    EPICS ||--o{ FEATURES : contains
    FEATURES ||--o{ TASKS : contains
    TASKS ||--o{ TASK_HISTORY : tracks

    EPICS {
        int id PK
        string key UK "E[0-9]{2,}"
        string title
        text description
        string status "draft|active|completed|archived"
        string priority "high|medium|low"
        string business_value
        timestamp created_at
        timestamp updated_at
    }

    FEATURES {
        int id PK
        int epic_id FK
        string key UK "E[0-9]{2,}-F[0-9]{2,}"
        string title
        text description
        string status
        float progress_pct "0.0-100.0"
        timestamp created_at
        timestamp updated_at
    }

    TASKS {
        int id PK
        int feature_id FK
        string key UK
        string title
        text description
        string status "todo|in_progress|blocked|ready_for_review|completed|archived"
        string agent_type "frontend|backend|api|testing|devops|general"
        int priority "1-10"
        text depends_on "JSON array"
        string assigned_agent
        string file_path
        string blocked_reason
        timestamp created_at
        timestamp started_at
        timestamp completed_at
        timestamp blocked_at
        timestamp updated_at
    }

    TASK_HISTORY {
        int id PK
        int task_id FK
        string old_status
        string new_status
        string agent
        text notes
        timestamp timestamp
    }
```

### Database Schema

#### Table: epics

```sql
CREATE TABLE epics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    key TEXT NOT NULL UNIQUE,
    title TEXT NOT NULL,
    description TEXT,
    status TEXT NOT NULL CHECK (status IN ('draft', 'active', 'completed', 'archived')),
    priority TEXT NOT NULL CHECK (priority IN ('high', 'medium', 'low')),
    business_value TEXT CHECK (business_value IN ('high', 'medium', 'low')),
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE UNIQUE INDEX idx_epics_key ON epics(key);
CREATE INDEX idx_epics_status ON epics(status);

CREATE TRIGGER epics_updated_at AFTER UPDATE ON epics
FOR EACH ROW BEGIN
    UPDATE epics SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
END;
```

#### Table: features

```sql
CREATE TABLE features (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    epic_id INTEGER NOT NULL,
    key TEXT NOT NULL UNIQUE,
    title TEXT NOT NULL,
    description TEXT,
    status TEXT NOT NULL CHECK (status IN ('draft', 'active', 'completed', 'archived')),
    progress_pct REAL NOT NULL DEFAULT 0.0 CHECK (progress_pct >= 0.0 AND progress_pct <= 100.0),
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (epic_id) REFERENCES epics(id) ON DELETE CASCADE
);

CREATE UNIQUE INDEX idx_features_key ON features(key);
CREATE INDEX idx_features_epic_id ON features(epic_id);
CREATE INDEX idx_features_status ON features(status);
```

#### Table: tasks

```sql
CREATE TABLE tasks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    feature_id INTEGER NOT NULL,
    key TEXT NOT NULL UNIQUE,
    title TEXT NOT NULL,
    description TEXT,
    status TEXT NOT NULL CHECK (status IN ('todo', 'in_progress', 'blocked', 'ready_for_review', 'completed', 'archived')),
    agent_type TEXT CHECK (agent_type IN ('frontend', 'backend', 'api', 'testing', 'devops', 'general')),
    priority INTEGER NOT NULL DEFAULT 5 CHECK (priority >= 1 AND priority <= 10),
    depends_on TEXT,
    assigned_agent TEXT,
    file_path TEXT,
    blocked_reason TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    blocked_at TIMESTAMP,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (feature_id) REFERENCES features(id) ON DELETE CASCADE
);

CREATE UNIQUE INDEX idx_tasks_key ON tasks(key);
CREATE INDEX idx_tasks_feature_id ON tasks(feature_id);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_agent_type ON tasks(agent_type);
CREATE INDEX idx_tasks_status_priority ON tasks(status, priority);
```

#### Table: task_history

```sql
CREATE TABLE task_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id INTEGER NOT NULL,
    old_status TEXT,
    new_status TEXT NOT NULL,
    agent TEXT,
    notes TEXT,
    timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE
);

CREATE INDEX idx_task_history_task_id ON task_history(task_id);
CREATE INDEX idx_task_history_timestamp ON task_history(timestamp DESC);
```

### Index Strategy

| Index | Purpose | Impact |
|-------|---------|--------|
| `idx_epics_key` | Unique key lookup | O(log n) key searches |
| `idx_epics_status` | Filter epics by status | Fast status queries |
| `idx_features_epic_id` | Join features to epics | Fast epic â†’ features lookups |
| `idx_features_status` | Filter features by status | Fast status queries |
| `idx_tasks_feature_id` | Join tasks to features | Fast feature â†’ tasks lookups |
| `idx_tasks_status` | Filter by task status | Fast status queries |
| `idx_tasks_agent_type` | Filter by agent type | Fast agent queries |
| `idx_tasks_status_priority` | Composite for priority queries | Fast workqueue sorting |
| `idx_task_history_task_id` | Task history lookup | Fast history queries |

### Progress Calculation Algorithms

#### Feature Progress

```sql
-- Formula: (completed + ready_for_review) / total * 100
SELECT
    (COUNT(CASE WHEN status IN ('completed', 'ready_for_review') THEN 1 END) * 100.0) /
    NULLIF(COUNT(*), 0) as progress_pct
FROM tasks
WHERE feature_id = ?
```

#### Epic Progress

```sql
-- Weighted average by task count
-- Features with more tasks contribute more to epic progress
SELECT
    COALESCE(SUM(f.progress_pct * task_count), 0) /
    NULLIF(SUM(task_count), 0) as epic_progress
FROM features f
LEFT JOIN (
    SELECT feature_id, COUNT(*) as task_count
    FROM tasks
    GROUP BY feature_id
) t ON f.id = t.feature_id
WHERE f.epic_id = ?
```

---

## Interface Contracts

### CLI Commands

#### Epic Commands

```bash
# List epics with progress
pm epic list [--status=active]

# Create epic
pm epic create --key=E05 --title="New Epic" --priority=high

# Show epic details with features
pm epic show E04

# Delete epic (cascades to features and tasks)
pm epic delete E04
```

#### Feature Commands

```bash
# List features for epic
pm feature list --epic=E04

# Create feature
pm feature create --epic=E04 --key=E04-F05 --title="New Feature"

# Show feature with tasks and progress
pm feature show E04-F01

# Update feature
pm feature update E04-F01 --status=completed
```

#### Task Commands

```bash
# List tasks
pm task list [--feature=E04-F01] [--status=todo] [--agent=backend]

# Create task
pm task create --feature=E04-F01 --key=E04-F01-T010 --title="Implement API" --priority=1

# Show task details
pm task show E04-F01-T010

# Status transitions
pm task start E04-F01-T010
pm task complete E04-F01-T010
pm task block E04-F01-T010 --reason="Waiting for API key"
pm task unblock E04-F01-T010

# Update task
pm task update E04-F01-T010 --priority=5 --agent-type=backend
```

### HTTP API

```
GET  /                  # Welcome message
GET  /health            # Health check (includes database ping)
```

**Future API Endpoints** (not yet implemented):

```
GET    /api/v1/epics
POST   /api/v1/epics
GET    /api/v1/epics/:key
PUT    /api/v1/epics/:key
DELETE /api/v1/epics/:key

GET    /api/v1/features
POST   /api/v1/features
GET    /api/v1/features/:key
PUT    /api/v1/features/:key

GET    /api/v1/tasks
POST   /api/v1/tasks
GET    /api/v1/tasks/:key
PUT    /api/v1/tasks/:key
PATCH  /api/v1/tasks/:key/status

GET    /api/v1/tasks/:key/history
```

---

## Non-Functional Requirements

### Performance

| Metric | Target | Current |
|--------|--------|---------|
| Task creation | < 10ms | ~2-5ms (SQLite local) |
| Task list query | < 50ms | ~10-20ms (with indexes) |
| Epic progress calc | < 100ms | ~30-50ms (optimized SQL) |
| Database size | < 1GB | ~10MB per 10k tasks |

**Optimization Strategies**:
- Indexes on all foreign keys
- Composite indexes for common queries
- WAL mode for better concurrency
- In-memory caching (future enhancement)

### Scalability

| Dimension | Limit | Notes |
|-----------|-------|-------|
| Concurrent users | 1-5 | Single SQLite writer limitation |
| Total tasks | 100,000+ | SQLite handles well |
| Tasks per feature | 1,000+ | Tested with pagination |
| Features per epic | 100+ | No known issues |

**Current Limitations**:
- Single-machine deployment
- Single SQLite database file
- No horizontal scaling

**Future Scale Options**:
1. PostgreSQL for multi-user scenarios
2. Read replicas for query scaling
3. Redis cache for hot data
4. API rate limiting

### Reliability

**Data Integrity**:
- âœ… Foreign key constraints
- âœ… Check constraints
- âœ… Unique constraints
- âœ… Transaction atomicity
- âœ… Cascade deletes

**Error Handling**:
- Explicit error checking on all operations
- Transaction rollback on failure
- Error context with `fmt.Errorf()` and `%w`
- Database integrity checks

**Backup Strategy**:
```bash
# SQLite backup
sqlite3 shark-tasks.db ".backup backup-$(date +%Y%m%d).db"

# Or file system copy (WAL-safe)
cp shark-tasks.db shark-tasks.db.backup
```

### Maintainability

**Code Quality**:
- Go fmt for consistent formatting
- go vet for static analysis
- golangci-lint for comprehensive linting
- Test coverage > 70% for repositories

**Documentation**:
- README with quick start
- API documentation (in progress)
- Architecture documentation (this document)
- Inline code comments for complex logic

**Testing Strategy**:
- Unit tests for models and validation
- Integration tests for repositories
- Benchmark tests for performance-critical paths
- Test utilities for common setup

---

## Deployment Architecture

### Current Deployment: Single Binary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Developer Machine                  â”‚
â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Shark CLI Tool                     â”‚ â”‚
â”‚  â”‚  (~/go/bin/pm)                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â†“                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SQLite Database                 â”‚ â”‚
â”‚  â”‚  (./shark-tasks.db)              â”‚ â”‚
â”‚  â”‚  â€¢ WAL mode                      â”‚ â”‚
â”‚  â”‚  â€¢ File-based locking            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Installation**:
```bash
make install-pm  # Installs to ~/go/bin/pm
export PATH=$PATH:$HOME/go/bin
pm --help
```

**Advantages**:
- Zero-configuration deployment
- Single binary (no dependencies)
- No server required
- Works offline
- Fast startup

**Disadvantages**:
- Single user at a time (SQLite limitation)
- No remote access
- No web UI
- Manual backups

### Future Deployment: Client-Server

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      HTTP       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Shark CLI Tool    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  â”‚   HTTP Server    â”‚
â”‚   (Client)       â”‚                  â”‚   (:8080)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      HTTP       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI         â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  â”‚   Repository     â”‚
â”‚   (Browser)      â”‚                  â”‚   Layer          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â†“
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚  PostgreSQL DB   â”‚
                                      â”‚  or SQLite       â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits**:
- Multi-user support
- Remote access
- Web UI option
- Centralized data
- Better for teams

**Trade-offs**:
- Requires server setup
- Network dependency
- More complex deployment
- Authentication needed

---

## Security Design

### Current Security Model

**Threat Model**: Single-user local deployment

| Threat | Mitigation | Status |
|--------|------------|--------|
| Unauthorized access | File system permissions | âœ… Implemented |
| Data corruption | Transactions + constraints | âœ… Implemented |
| SQL injection | Parameterized queries | âœ… Implemented |
| Data loss | Manual backups | ðŸ”¸ User responsibility |

**Database Security**:
- File permissions: `0600` (owner read/write only)
- No network exposure
- Foreign key constraints prevent orphaned records
- Check constraints validate data

**SQL Injection Prevention**:
```go
// âœ… SAFE: Parameterized query
query := "SELECT * FROM tasks WHERE id = ?"
db.QueryRow(query, taskID)

// âŒ UNSAFE: String concatenation (not used in codebase)
query := "SELECT * FROM tasks WHERE id = " + taskID
```

### Future Security Enhancements

**For Client-Server Deployment**:

1. **Authentication**
   - JWT tokens for API access
   - API key authentication for CLI
   - Session management

2. **Authorization**
   - Role-based access control (RBAC)
   - Epic/Feature ownership
   - Task assignment validation

3. **Encryption**
   - TLS for API communication
   - Encrypted database (SQLCipher)
   - Encrypted backups

4. **Audit Logging**
   - User action logging
   - Authentication events
   - Data modification history (partially implemented via task_history)

---

## Operations & Monitoring

### Logging Strategy

**Current Logging**:
```go
log.Println("Database initialized successfully")
log.Fatal("Failed to initialize database:", err)
```

**Recommended Structured Logging**:
```go
import "log/slog"

logger := slog.New(slog.NewJSONHandler(os.Stdout, nil))
logger.Info("database initialized",
    "path", dbPath,
    "duration_ms", duration.Milliseconds(),
)
logger.Error("failed to create task",
    "error", err,
    "task_key", task.Key,
)
```

### Monitoring

**Health Checks**:
```bash
# HTTP health check
curl http://localhost:8080/health

# CLI health check
pm epic list >/dev/null && echo "OK" || echo "FAIL"
```

**Metrics to Monitor** (future):
- Task creation rate
- Average task completion time
- Tasks blocked count
- Database file size
- Query performance

### Backup & Recovery

**Backup Strategy**:

1. **Hot Backup** (while database running):
```bash
sqlite3 shark-tasks.db ".backup backup.db"
```

2. **File Copy** (WAL-safe):
```bash
cp shark-tasks.db shark-tasks.backup.db
```

3. **Export to SQL**:
```bash
sqlite3 shark-tasks.db .dump > backup.sql
```

**Recovery**:
```bash
# From backup file
cp backup.db shark-tasks.db

# From SQL dump
sqlite3 shark-tasks-new.db < backup.sql
```

**Automated Backup** (recommended):
```bash
# Crontab entry - daily backup at 2 AM
0 2 * * * cd /path/to/project && make backup
```

### Disaster Recovery

**RTO (Recovery Time Objective)**: < 5 minutes
**RPO (Recovery Point Objective)**: Daily backups = up to 24 hours data loss

**Recovery Procedures**:

1. **Database corruption**:
   - Run integrity check: `PRAGMA integrity_check;`
   - Restore from most recent backup
   - Re-run any missed operations

2. **Accidental deletion**:
   - Restore from backup
   - Use task_history table to identify what was deleted
   - Manual reconstruction if needed

3. **File system failure**:
   - Restore database file from backup
   - Verify with integrity check

---

## Design Patterns

### Patterns Used

1. **Repository Pattern** âœ…
   - Abstracts data access
   - Centralizes queries
   - Testable via interfaces (future)

2. **Constructor Injection** âœ…
   ```go
   func NewTaskRepository(db *DB) *TaskRepository
   ```

3. **Builder Pattern** (implicit via struct initialization)
   ```go
   task := &models.Task{
       Key: "E04-F01-T001",
       Title: "Implement feature",
       Priority: 1,
   }
   ```

4. **Transaction Script** âœ…
   - Each repository method is a transaction script
   - Simple, clear, easy to understand

5. **Factory Pattern** âœ…
   ```go
   func NewDB(db *sql.DB) *DB
   ```

### Anti-Patterns Avoided

âŒ **God Object**: Each component has clear, limited responsibility
âŒ **Tight Coupling**: Repositories don't depend on CLI or HTTP layers
âŒ **Magic Numbers**: Constants defined (TaskStatus, Priority)
âŒ **Premature Optimization**: Simple, clear code over clever optimizations

---

## Future Enhancements

### Phase 1: Enhanced Testability
- Add repository interfaces
- Context-aware methods
- Mock implementations for testing

### Phase 2: Advanced Features
- Dependency graph visualization
- Task templates
- Bulk operations
- Search functionality

### Phase 3: Multi-User Support
- PostgreSQL backend
- HTTP API expansion
- Authentication/Authorization
- Web UI

### Phase 4: Advanced Analytics
- Progress trending
- Velocity metrics
- Burndown charts
- Bottleneck detection

---

## Conclusion

The Shark Task Manager demonstrates solid software architecture following Go best practices and clean architecture principles. The system is:

âœ… **Well-Structured**: Clear separation of concerns
âœ… **Maintainable**: Consistent patterns throughout
âœ… **Testable**: Good test coverage with proper test organization
âœ… **Performant**: Optimized queries with proper indexing
âœ… **Reliable**: Transaction safety and data integrity

**Primary Strength**: Simplicity and clarity over unnecessary complexity

**Primary Opportunity**: Add interfaces for better testability and future PostgreSQL support

The architecture is production-ready for its intended use case (single-user, local development) and provides a solid foundation for future enhancements.
