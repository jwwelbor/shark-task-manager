---
task_key: T-E07-F24-006
feature_key: E07-F24
title: "Phase 6: Integration testing and polish"
status: todo
agent: qa
priority: 7
estimated_hours: 2-3
dependencies:
  - T-E07-F24-001
  - T-E07-F24-002
  - T-E07-F24-003
  - T-E07-F24-004
  - T-E07-F24-005
related_docs:
  - ../technical-design.md
  - ../specifications/business-requirements.md
---

# Task: Phase 6 - Integration Testing and Polish

**Feature**: E07-F24 - Workflow Profile Support
**Phase**: 6 of 6
**Estimated Time**: 2-3 hours

## Objective

Perform comprehensive end-to-end testing of the workflow profile feature, refine error messages, handle edge cases, optimize performance, and ensure backward compatibility with existing Shark installations.

## Testing Scope

### 1. End-to-End Testing
- Complete workflow from fresh install to profile application
- Multi-profile switching scenarios
- Migration scenarios (basic → advanced, advanced → basic)

### 2. Error Handling
- Invalid profile names
- Corrupted config files
- Permission errors
- Missing files

### 3. Edge Cases
- Empty configurations
- Partial configurations
- Custom status metadata
- Cloud database configs (Turso)

### 4. Performance
- Command execution time (<100ms target)
- Memory usage
- File I/O optimization

### 5. Backward Compatibility
- Existing configs without profiles
- Configs with custom fields
- Migration from older versions

## Implementation Plan

### Step 1: Create End-to-End Test Suite

Create `tests/e2e/workflow_profiles_test.go`:

```go
package e2e

import (
    "os"
    "os/exec"
    "path/filepath"
    "testing"
    "encoding/json"
)

func TestE2E_FreshInstall_BasicProfile(t *testing.T) {
    // Setup: Create temp project directory
    tmpDir := t.TempDir()
    os.Chdir(tmpDir)

    // Step 1: Initialize shark
    cmd := exec.Command("shark", "init", "--non-interactive")
    output, err := cmd.CombinedOutput()
    if err != nil {
        t.Fatalf("shark init failed: %v\nOutput: %s", err, output)
    }

    // Step 2: Verify config created with basic profile (default)
    configPath := filepath.Join(tmpDir, ".sharkconfig.json")
    if _, err := os.Stat(configPath); os.IsNotExist(err) {
        t.Fatal("Config file not created")
    }

    // Step 3: Verify basic profile statuses present
    configData, _ := os.ReadFile(configPath)
    var config map[string]interface{}
    json.Unmarshal(configData, &config)

    statusMeta := config["status_metadata"].(map[string]interface{})
    if len(statusMeta) != 5 {
        t.Errorf("Expected 5 statuses, got %d", len(statusMeta))
    }

    // Verify basic profile statuses
    expectedStatuses := []string{"todo", "in_progress", "ready_for_review", "completed", "blocked"}
    for _, status := range expectedStatuses {
        if _, exists := statusMeta[status]; !exists {
            t.Errorf("Missing expected status: %s", status)
        }
    }
}

func TestE2E_ProfileSwitch_BasicToAdvanced(t *testing.T) {
    // Setup: Initialize with basic profile
    tmpDir := t.TempDir()
    os.Chdir(tmpDir)

    cmd := exec.Command("shark", "init", "--non-interactive")
    cmd.Run()

    // Step 1: Apply advanced profile
    cmd = exec.Command("shark", "init", "update", "--workflow=advanced")
    output, err := cmd.CombinedOutput()
    if err != nil {
        t.Fatalf("shark init update failed: %v\nOutput: %s", err, output)
    }

    // Step 2: Verify advanced profile applied
    configPath := filepath.Join(tmpDir, ".sharkconfig.json")
    configData, _ := os.ReadFile(configPath)
    var config map[string]interface{}
    json.Unmarshal(configData, &config)

    statusMeta := config["status_metadata"].(map[string]interface{})
    if len(statusMeta) < 16 {
        t.Errorf("Expected 16+ statuses for advanced profile, got %d", len(statusMeta))
    }

    // Verify status_flow exists
    if _, exists := config["status_flow"]; !exists {
        t.Error("Missing status_flow in advanced profile")
    }

    // Verify special_statuses exists
    if _, exists := config["special_statuses"]; !exists {
        t.Error("Missing special_statuses in advanced profile")
    }

    // Step 3: Verify backup created
    backupFiles, _ := filepath.Glob(tmpDir + "/.sharkconfig.json.backup.*")
    if len(backupFiles) == 0 {
        t.Error("No backup file created")
    }
}

func TestE2E_DryRun_NoChanges(t *testing.T) {
    // Setup
    tmpDir := t.TempDir()
    os.Chdir(tmpDir)

    cmd := exec.Command("shark", "init", "--non-interactive")
    cmd.Run()

    // Get original config
    configPath := filepath.Join(tmpDir, ".sharkconfig.json")
    originalData, _ := os.ReadFile(configPath)

    // Step 1: Run dry-run
    cmd = exec.Command("shark", "init", "update", "--workflow=advanced", "--dry-run")
    output, err := cmd.CombinedOutput()
    if err != nil {
        t.Fatalf("dry-run failed: %v\nOutput: %s", err, output)
    }

    // Step 2: Verify config unchanged
    currentData, _ := os.ReadFile(configPath)
    if string(originalData) != string(currentData) {
        t.Error("Config changed during dry-run (should be unchanged)")
    }

    // Step 3: Verify output mentions dry-run
    outputStr := string(output)
    if !contains(outputStr, "DRY RUN") && !contains(outputStr, "dry_run") {
        t.Error("Output should indicate dry-run mode")
    }
}

func TestE2E_PreserveDatabase(t *testing.T) {
    // Test that database config is preserved
}

func TestE2E_InvalidProfile(t *testing.T) {
    // Test error handling for invalid profile names
}

func TestE2E_JSONOutput(t *testing.T) {
    // Test JSON output format
}

// Helper function
func contains(s, substr string) bool {
    return strings.Contains(s, substr)
}
```

### Step 2: Error Message Refinement

Review and improve error messages in:

**`internal/init/profiles.go`:**
```go
func GetProfile(name string) (*WorkflowProfile, error) {
    profile, exists := profileRegistry[strings.ToLower(name)]
    if !exists {
        available := strings.Join(ListProfileNames(), ", ")
        return nil, fmt.Errorf("profile not found: %s\n\nAvailable profiles: %s\n\nUse 'shark init update --workflow=<profile>' to apply a profile",
            name, available)
    }
    return profile, nil
}
```

**`internal/init/profile_service.go`:**
```go
func (s *ProfileService) ApplyProfile(opts UpdateOptions) (*UpdateResult, error) {
    // Enhanced error messages
    currentConfig, err := s.configManager.Load()
    if err != nil && !os.IsNotExist(err) {
        return nil, fmt.Errorf("failed to load config: %w\n\nCheck file permissions and JSON syntax", err)
    }

    // ... rest of implementation
}
```

### Step 3: Edge Case Handling

**Empty Config:**
```go
func TestApplyProfile_EmptyConfig(t *testing.T) {
    // Test applying profile to empty config file
    tmpDir := t.TempDir()
    configPath := filepath.Join(tmpDir, ".sharkconfig.json")

    // Create empty config
    os.WriteFile(configPath, []byte("{}"), 0644)

    service := NewProfileService(configPath)
    result, err := service.ApplyProfile(UpdateOptions{
        ConfigPath:   configPath,
        WorkflowName: "basic",
    })

    if err != nil {
        t.Fatalf("Failed to apply profile to empty config: %v", err)
    }

    // Verify basic profile applied
    // ...
}
```

**Corrupted JSON:**
```go
func TestApplyProfile_CorruptedJSON(t *testing.T) {
    tmpDir := t.TempDir()
    configPath := filepath.Join(tmpDir, ".sharkconfig.json")

    // Create corrupted JSON
    os.WriteFile(configPath, []byte("{invalid json"), 0644)

    service := NewProfileService(configPath)
    _, err := service.ApplyProfile(UpdateOptions{
        ConfigPath:   configPath,
        WorkflowName: "basic",
    })

    if err == nil {
        t.Error("Expected error for corrupted JSON")
    }

    // Verify error message is helpful
    if !strings.Contains(err.Error(), "JSON") {
        t.Error("Error message should mention JSON syntax")
    }
}
```

**Permission Errors:**
```go
func TestApplyProfile_PermissionDenied(t *testing.T) {
    // Test handling of read-only config files
}
```

**Cloud Database Config:**
```go
func TestApplyProfile_TursoDatabase(t *testing.T) {
    // Test that Turso database config is preserved
    tmpDir := t.TempDir()
    configPath := filepath.Join(tmpDir, ".sharkconfig.json")

    // Create config with Turso
    tursoConfig := `{
        "database": {
            "backend": "turso",
            "url": "libsql://shark-test.turso.io",
            "auth_token_file": "/path/to/token"
        }
    }`
    os.WriteFile(configPath, []byte(tursoConfig), 0644)

    service := NewProfileService(configPath)
    result, err := service.ApplyProfile(UpdateOptions{
        ConfigPath:   configPath,
        WorkflowName: "basic",
    })

    if err != nil {
        t.Fatalf("Failed: %v", err)
    }

    // Verify Turso config preserved
    configData, _ := os.ReadFile(configPath)
    var config map[string]interface{}
    json.Unmarshal(configData, &config)

    db := config["database"].(map[string]interface{})
    if db["backend"] != "turso" {
        t.Error("Turso backend should be preserved")
    }
}
```

### Step 4: Performance Optimization

**Benchmark Tests:**
```go
func BenchmarkApplyProfile_Basic(b *testing.B) {
    tmpDir := b.TempDir()
    configPath := filepath.Join(tmpDir, ".sharkconfig.json")
    service := NewProfileService(configPath)

    opts := UpdateOptions{
        ConfigPath:   configPath,
        WorkflowName: "basic",
    }

    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        service.ApplyProfile(opts)
    }
}

func BenchmarkMerge_LargeConfig(b *testing.B) {
    // Benchmark merge performance with large configs
}
```

**Target Performance:**
- Total command execution: <100ms
- Config merge: <5ms
- File write: <10ms
- JSON parsing: <10ms

**Optimization Checklist:**
- [ ] Minimize allocations in merge logic
- [ ] Reuse config.Manager instance
- [ ] Optimize deep copy operations
- [ ] Profile memory usage
- [ ] Check for goroutine leaks

### Step 5: Backward Compatibility Testing

**Legacy Config (No Profiles):**
```go
func TestBackwardCompatibility_LegacyConfig(t *testing.T) {
    // Test that old configs still work
    tmpDir := t.TempDir()
    configPath := filepath.Join(tmpDir, ".sharkconfig.json")

    // Create legacy config (no status_metadata)
    legacyConfig := `{
        "database": {
            "backend": "local",
            "url": "./shark-tasks.db"
        },
        "color_enabled": true
    }`
    os.WriteFile(configPath, []byte(legacyConfig), 0644)

    // Apply basic profile (should add status_metadata)
    service := NewProfileService(configPath)
    result, err := service.ApplyProfile(UpdateOptions{
        ConfigPath:   configPath,
        WorkflowName: "basic",
    })

    if err != nil {
        t.Fatalf("Failed: %v", err)
    }

    // Verify legacy fields preserved
    if !contains(result.Changes.Preserved, "database") {
        t.Error("Database config should be preserved")
    }
    if !contains(result.Changes.Preserved, "color_enabled") {
        t.Error("color_enabled should be preserved")
    }
}
```

**Custom Status Metadata:**
```go
func TestBackwardCompatibility_CustomStatuses(t *testing.T) {
    // Test that custom statuses are preserved (unless --force)
}
```

### Step 6: Final Polish

**CLI Output Refinement:**
- Ensure colors work correctly with `color_enabled` setting
- Test output on different terminal types
- Verify JSON output is properly formatted
- Check that verbose mode provides useful info

**Documentation Review:**
- Verify all code examples work
- Test all documented workflows
- Check error message accuracy
- Validate troubleshooting steps

**Code Cleanup:**
- Remove debug logging
- Add final code comments
- Ensure consistent naming
- Run `go fmt` and `go vet`

## Acceptance Criteria

- [x] **AC1**: All end-to-end tests pass
- [x] **AC2**: All edge cases handled gracefully
- [x] **AC3**: Error messages are clear and actionable
- [x] **AC4**: Command execution time <100ms
- [x] **AC5**: No memory leaks detected
- [x] **AC6**: Backward compatibility maintained
- [x] **AC7**: Test coverage >85%
- [x] **AC8**: All benchmark targets met
- [x] **AC9**: Documentation examples all work
- [x] **AC10**: Code passes all linters

## Test Plan

### Full Test Suite

```bash
# Run all unit tests
go test -v ./internal/init/...

# Run integration tests
go test -v ./internal/cli/commands/...

# Run end-to-end tests
go test -v ./tests/e2e/...

# Check total coverage
go test -cover ./...

# Run benchmarks
go test -bench=. ./internal/init/...

# Memory profiling
go test -memprofile=mem.prof ./internal/init/...
go tool pprof mem.prof

# Race detection
go test -race ./internal/init/...
```

### Manual Testing Checklist

- [ ] Fresh install with basic profile
- [ ] Fresh install then apply advanced profile
- [ ] Switch from basic to advanced
- [ ] Switch from advanced to basic (with --force)
- [ ] Dry-run mode shows correct preview
- [ ] Force mode overwrites correctly
- [ ] JSON output valid
- [ ] Invalid profile shows error
- [ ] Corrupted config shows clear error
- [ ] Permission errors handled
- [ ] Turso database config preserved
- [ ] Custom fields preserved
- [ ] Backup created successfully
- [ ] Backup can be restored

### Performance Testing

```bash
# Measure command execution time
time shark init update --workflow=basic

# Expected: <100ms total
```

## Dependencies

**Requires**:
- T-E07-F24-001 (Phase 1: Data structures)
- T-E07-F24-002 (Phase 2: ConfigMerger)
- T-E07-F24-003 (Phase 3: ProfileService)
- T-E07-F24-004 (Phase 4: CLI command)
- T-E07-F24-005 (Phase 5: Documentation)

**Blocks**:
- None (final phase)

## Design References

- **Technical Design**: Section "Implementation Phases - Phase 6" (lines 1157-1175)
- **Testing Strategy**: Section "Testing Strategy" (lines 981-1046)
- **Performance Considerations**: Section "Performance Considerations" (lines 1217-1254)

## Success Indicators

✅ All tests passing (unit + integration + e2e)
✅ Test coverage >85%
✅ Command execution <100ms
✅ No memory leaks
✅ Error messages helpful
✅ Edge cases handled
✅ Backward compatible
✅ Documentation accurate
✅ Code clean and well-commented

## Notes

- **Priority**: Focus on end-to-end testing first
- **Performance**: Profile before optimizing
- **Errors**: Test all error paths, not just happy path
- **Compatibility**: Test with real legacy configs
- **Polish**: This is the final phase - make it production-ready
- Use `go test -race` to detect race conditions
- Use `go test -cover` to ensure coverage targets met
- Profile with `pprof` if performance issues found

## Common Issues to Test

1. **Concurrent access** - Multiple shark commands running simultaneously
2. **Partial writes** - Disk full or process killed during write
3. **Unicode in configs** - Special characters in status names
4. **Large configs** - Configs with hundreds of custom fields
5. **Symlinks** - Config file is a symlink
6. **Network drives** - Config on network mount (slow I/O)

## Estimated Breakdown

- End-to-end test suite: 45 min
- Error message refinement: 20 min
- Edge case handling: 30 min
- Performance testing and optimization: 30-40 min
- Backward compatibility tests: 20 min
- Final polish and cleanup: 15-20 min
- **Total**: 2-3 hours
