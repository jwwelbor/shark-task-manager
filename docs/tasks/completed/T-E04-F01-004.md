---
task_key: T-E04-F01-004
status: completed
feature: /home/jwwelbor/.claude/docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema
created: 2025-12-14
assigned_agent: general-purpose
dependencies: ["T-E04-F01-003"]
estimated_time: 8 hours
file_path: /home/jwwelbor/.claude/docs/tasks/todo/T-E04-F01-004.md
---

# PRP: Integration Tests & Performance Validation

## Goal

Implement comprehensive integration tests that validate end-to-end database functionality, foreign key enforcement, cascade deletes, transaction rollback, and performance benchmarks to ensure all PRD requirements are met.

## Success Criteria

- [ ] Integration tests for complete epic → feature → task creation flow
- [ ] Cascade delete tests verify epic deletion removes all children
- [ ] Foreign key constraint tests prevent orphaned records
- [ ] Transaction rollback tests verify multi-step operation atomicity
- [ ] Progress calculation integration tests with real data
- [ ] Atomic status update tests (task + history in single transaction)
- [ ] Performance benchmarks meet all PRD targets (<500ms init, <50ms insert, <100ms filter with 10K tasks)
- [ ] Large dataset tests with 10,000 tasks for performance validation
- [ ] All integration tests pass consistently
- [ ] Tests can run in parallel with isolated databases
- [ ] No database corruption after test execution

## Implementation Guidance

### Overview

This phase validates that all database components work together correctly through integration tests and performance benchmarks. You'll test complex multi-table operations, constraint enforcement, transaction behavior, and performance under load to ensure the database layer meets all PRD specifications.

### Key Requirements

- **Integration Test Fixtures**: Create as specified in [Implementation Phases - Phase 4](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/08-implementation-phases.md#phase-4-integration-tests)
  - Temporary database fixture (file-based, not in-memory) for realistic testing
  - Populated database fixture with sample epic, features, and tasks
  - Large dataset fixture with 10,000 tasks for performance testing
  - All fixtures use tmp_path for isolation and cleanup

- **End-to-End Flow Tests**: Verify complete workflows in [Test Criteria - Integration Tests](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/09-test-criteria.md#test-complete-epic-creation-flow)
  - Create epic → create features → create tasks → verify relationships
  - Query task via epic (JOIN through features table)
  - Update task → verify feature progress recalculated
  - Multi-criteria filtering across joined tables

- **Constraint Enforcement Tests**: Validate data integrity in [Test Criteria - Foreign Key Constraints](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/09-test-criteria.md#test-foreign-key-prevents-orphan-feature)
  - Foreign key prevents orphan features (invalid epic_id)
  - Foreign key prevents orphan tasks (invalid feature_id)
  - Cascade delete propagates: epic → features → tasks → history
  - Unique constraints prevent duplicate keys

- **Transaction Behavior Tests**: Verify atomicity in [Test Criteria - Transaction Rollback](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/09-test-criteria.md#test-transaction-rollback-on-error)
  - Multi-step operation rolls back on error
  - Task status + history creation atomic
  - Partial updates never persist

- **Performance Benchmarks**: Meet all PRD targets in [Test Criteria - Performance Tests](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/09-test-criteria.md#6-performance-benchmarks-testsperformancetest_database_performancepy)
  - Database initialization <500ms
  - Single task INSERT <50ms
  - get_by_key <10ms (with 10K tasks)
  - Filter query <100ms (with 10K tasks)
  - Progress calculation <200ms (50 features)
  - Bulk INSERT (100 tasks) <2,000ms
  - CASCADE DELETE <500ms (1000 tasks)

### Files to Create/Modify

**New Files**:
- `tests/integration/test_database_operations.py` - End-to-end integration tests (~400 lines)
- `tests/performance/test_database_performance.py` - Performance benchmarks (~300 lines)
- `tests/fixtures/sample_data.py` - Sample data generators (~200 lines)
- `tests/conftest.py` - Shared pytest fixtures (if not exists)

### Integration Points

- **All Previous Phases**: Integration tests exercise models, session management, and repositories together
- **Future CLI** (E04-F02): CLI integration will follow same patterns validated here
- **Future Features** (E04-F03+): Establishes testing patterns for future features

Reference [Architecture - Testing Architecture](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/02-architecture.md#testing-architecture) for testing strategy.

## Validation Gates

- **Integration Test Pass Rate**: 100% of integration tests passing
  - Epic → Feature → Task creation flow
  - Cascade delete verification
  - Foreign key constraint enforcement
  - Transaction rollback behavior
  - Progress calculation accuracy
  - Atomic status update + history

- **Performance Benchmarks**: All benchmarks meet PRD targets
  - Run performance tests: `pytest tests/performance/ -v`
  - Verify each benchmark assertion passes
  - No performance regressions from baseline
  - Index usage verified for queries

- **Test Isolation**: Tests run successfully in parallel
  - Run `pytest -n auto tests/integration/`
  - Each test uses isolated temp database
  - No test interference or shared state
  - Cleanup successful (no temp files left)

- **Data Integrity**: No corruption after tests
  - Run `PRAGMA integrity_check` after test suite
  - Verify all constraints still enforced
  - Verify no orphaned records
  - Verify schema matches expected

- **Coverage**: Integration tests complement unit tests
  - Integration tests cover cross-component workflows
  - Performance tests use realistic data volumes
  - Edge cases covered (0 tasks, max tasks, etc.)

## Context & Resources

- **PRD Requirements**: [Performance NFRs](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/prd.md#non-functional-requirements)
  - Database initialization: <500ms
  - INSERT operations: <50ms
  - SELECT queries with filters: <100ms (10K tasks)
  - Progress calculation: <200ms (50 features)
  - Batch INSERT: <2 seconds (100 tasks)
- **Test Criteria**: [Integration Tests](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/09-test-criteria.md#integration-tests)
  - [Performance Benchmarks](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/09-test-criteria.md#6-performance-benchmarks-testsperformancetest_database_performancepy)
- **Architecture**: [Testing Architecture](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/02-architecture.md#testing-architecture)
- **Implementation Phases**: [Phase 4 Details](../docs/plan/E04-task-mgmt-cli-core/E04-F01-database-schema/08-implementation-phases.md#phase-4-integration-tests)

## Notes for Agent

- **File-Based Databases**: Integration tests must use temp file databases (not :memory:) to properly test file permissions, WAL mode, and realistic I/O performance.
- **Fixture Cleanup**: Use pytest's tmp_path fixture which auto-cleans. Database files created in tmp_path are automatically deleted after tests.
- **Performance Measurement**: Use `time.time()` before/after operations. Convert to milliseconds: `(end - start) * 1000`. Assert duration < target.
- **Large Dataset Generation**: For 10K task fixture, use bulk INSERT in single transaction for speed. Generate unique keys using f-string: `f"T-E04-F01-{i:03d}"`.
- **Cascade Delete Verification**: After deleting epic, query features and tasks tables directly to verify they're empty. Don't rely on ORM relationships.
- **Transaction Testing**: Force exception mid-transaction to test rollback. Use `with pytest.raises(Exception): ...` to catch and verify rollback occurred.
- **Index Verification**: Use `EXPLAIN QUERY PLAN` to verify SQLite uses indexes. Check output contains "USING INDEX idx_name".
- **Parallel Testing**: Use pytest-xdist plugin (`pytest -n auto`). Each test gets isolated tmp_path automatically.
- **Performance Variance**: Allow small margin for performance tests (e.g., target <50ms, assert <60ms). CI environments may be slower than local.
